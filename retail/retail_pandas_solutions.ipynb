{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "942e6b85",
   "metadata": {},
   "source": [
    "## 1. Load the dataset and display the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715ed78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('retail_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c75d1d",
   "metadata": {},
   "source": [
    "## 2. Display the summary statistics of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1a2d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6b64ce",
   "metadata": {},
   "source": [
    "## 3. Check for missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d23fe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e0a912",
   "metadata": {},
   "source": [
    "## 4. Drop rows with any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77745324",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f22359b",
   "metadata": {},
   "source": [
    "## 5. Fill missing values with the mean for numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bb7ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df.mean(), inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cec734",
   "metadata": {},
   "source": [
    "## 6. Fill missing values with the mode for categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc465cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df.mode().iloc[0], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dbbd2e",
   "metadata": {},
   "source": [
    "## 7. Create a new column 'Revenue' by multiplying 'Quantity' and 'Unit_Price'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a958fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Revenue'] = df['Quantity'] * df['Unit_Price']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13e6cf0",
   "metadata": {},
   "source": [
    "## 8. Calculate the correlation matrix for numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae979ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc90998",
   "metadata": {},
   "source": [
    "## 9. Plot a histogram for the 'Total_Price' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90da9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total_Price'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d3135a",
   "metadata": {},
   "source": [
    "## 10. Plot a bar chart for the 'Store_Location' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254b371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Store_Location'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adf09cc",
   "metadata": {},
   "source": [
    "## 11. Plot a scatter plot between 'Unit_Price' and 'Total_Price'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae65eff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='Unit_Price', y='Total_Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565b7916",
   "metadata": {},
   "source": [
    "## 12. Encode the 'Payment_Type' column using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23248f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['Payment_Type'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24303a0",
   "metadata": {},
   "source": [
    "## 13. Normalize the 'Total_Price' column using Min-Max scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9250f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df['Total_Price'] = scaler.fit_transform(df[['Total_Price']])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e10f67",
   "metadata": {},
   "source": [
    "## 14. Standardize the 'Discount' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d95dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df['Discount'] = scaler.fit_transform(df[['Discount']])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c164e3",
   "metadata": {},
   "source": [
    "## 15. Create a pivot table showing the average 'Total_Price' for each 'Store_Location'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8265ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(values='Total_Price', index='Store_Location', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554bba4b",
   "metadata": {},
   "source": [
    "## 16. Group the data by 'Return_Status' and calculate the mean 'Total_Price'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c9a81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Return_Status')['Total_Price'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2286536",
   "metadata": {},
   "source": [
    "## 17. Filter the dataset for orders with 'Total_Price' greater than 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12931f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[df['Total_Price'] > 1000]\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef15d1a",
   "metadata": {},
   "source": [
    "## 18. Sort the dataset by 'Purchase_Date' in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427a4a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='Purchase_Date', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec143ae0",
   "metadata": {},
   "source": [
    "## 19. Create a new column 'Final_Price' by subtracting 'Discount' from 'Total_Price'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3579ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Final_Price'] = df['Total_Price'] - df['Discount']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd5c8ab",
   "metadata": {},
   "source": [
    "## 20. Replace all instances of 'Returned' in the 'Return_Status' column with 'Processed'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f588d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Return_Status'].replace('Returned', 'Processed', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54536bfa",
   "metadata": {},
   "source": [
    "## 21. Rename the column 'Total_Price' to 'Order_Value'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Total_Price': 'Order_Value'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eec5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc4ff17",
   "metadata": {},
   "source": [
    "## 23. Check for duplicate rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e01d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f13900",
   "metadata": {},
   "source": [
    "## 24. Drop any duplicate rows found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219979d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e6da58",
   "metadata": {},
   "source": [
    "## 25. Create a new DataFrame containing only 'Order_ID', 'Customer_ID', and 'Order_Value'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c50f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df[['Order_ID', 'Customer_ID', 'Order_Value']]\n",
    "df_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7450d610",
   "metadata": {},
   "source": [
    "## 26. Merge the new DataFrame with the original dataset on 'Order_ID'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2502f41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_subset, df, on='Order_ID')\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a13676",
   "metadata": {},
   "source": [
    "## 27. Create a cross-tabulation of 'Store_Location' and 'Payment_Type'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceb8a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['Store_Location'], df['Payment_Type_Credit Card'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390a5b58",
   "metadata": {},
   "source": [
    "## 28. Create a pivot table showing the count of orders by 'Store_Location' and 'Return_Status'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d2a6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(index='Store_Location', columns='Return_Status', aggfunc='size', fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ededc1",
   "metadata": {},
   "source": [
    "## 29. Replace missing values in 'Discount' with the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fdeede",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Discount'].fillna(df['Discount'].median(), inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7046804e",
   "metadata": {},
   "source": [
    "## 30. Calculate the Z-score for the 'Unit_Price' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b2731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "df['Unit_Price_Zscore'] = zscore(df['Unit_Price'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c9f3dc",
   "metadata": {},
   "source": [
    "## 31. Filter out outliers in the 'Unit_Price' column based on Z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffadfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outliers = df[(df['Unit_Price_Zscore'] > -3) & (df['Unit_Price_Zscore'] < 3)]\n",
    "df_no_outliers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f304e9",
   "metadata": {},
   "source": [
    "## 32. Apply a lambda function to the 'Order_Value' column to categorize into 'Low', 'Medium', 'High'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac51ff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Order_Value_Category'] = df['Order_Value'].apply(lambda x: 'Low' if x < 500 else 'Medium' if x < 1500 else 'High')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d27512",
   "metadata": {},
   "source": [
    "## 33. Create a new column 'Profit' by subtracting 'Discount' from 'Revenue'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248e5b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Profit'] = df['Revenue'] - df['Discount']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12d62d5",
   "metadata": {},
   "source": [
    "## 34. Extract the year from 'Purchase_Date' and create a new column 'Purchase_Year'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5691717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Purchase_Date'] = df['Purchase_Date'].astype('datetime64')\n",
    "df['Purchase_Year'] = df['Purchase_Date'].dt.year\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc07f545",
   "metadata": {},
   "source": [
    "## 35. Convert the 'Return_Status' column to a categorical data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde7e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Return_Status'] = df['Return_Status'].astype('category')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebbd0c0",
   "metadata": {},
   "source": [
    "## 36. Create a box plot for 'Order_Value' across different 'Store_Location'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10462df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column='Order_Value', by='Store_Location')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caafcc64",
   "metadata": {},
   "source": [
    "## 37. Create a line plot showing the trend of 'Order_Value' over 'Purchase_Date'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20407dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Purchase_Date')['Order_Value'].mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3fe85d",
   "metadata": {},
   "source": [
    "## 38. Create a heatmap for the correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea61d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29577f76",
   "metadata": {},
   "source": [
    "## 39. Filter the dataset to include only orders with 'Return_Status' as 'Not Returned'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4b5108",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_returned = df[df['Return_Status'] == 'Not Returned']\n",
    "df_not_returned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811e2aec",
   "metadata": {},
   "source": [
    "## 40. Replace outliers in 'Revenue' with the median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edf86c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_value = df['Revenue'].median()\n",
    "df.loc[df['Revenue'] > df['Revenue'].quantile(0.99), 'Revenue'] = median_value\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aec305",
   "metadata": {},
   "source": [
    "## 41. Calculate the percentage of missing values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5e90de",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percent = df.isnull().mean() * 100\n",
    "missing_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc4f39d",
   "metadata": {},
   "source": [
    "## 42. Reorder the columns so that 'Order_ID' is the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40199d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Order_ID'] + [col for col in df.columns if col != 'Order_ID']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930d259e",
   "metadata": {},
   "source": [
    "## 43. Create a column 'High_Value_Order' which is True if 'Order_Value' > 2000, else False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747fa789",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['High_Value_Order'] = df['Order_Value'] > 2000\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8237fd8",
   "metadata": {},
   "source": [
    "## 44. Split the dataset into training (80%) and testing (20%) sets based on 'Order_ID'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848bd342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800a3aca",
   "metadata": {},
   "source": [
    "## 45. Create a pipeline to preprocess the 'Order_Value' and 'Unit_Price' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b59536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "df[['Order_Value', 'Unit_Price']] = pipeline.fit_transform(df[['Order_Value', 'Unit_Price']])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce5734c",
   "metadata": {},
   "source": [
    "## 46. Export the cleaned dataset to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db433059",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_retail_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a5e326",
   "metadata": {},
   "source": [
    "## 47. Save the dataset in Excel format with multiple sheets based on 'Store_Location'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b8f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('retail_by_location.xlsx') as writer:\n",
    "    for location in df['Store_Location'].unique():\n",
    "        df[df['Store_Location'] == location].to_excel(writer, sheet_name=location, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559c346b",
   "metadata": {},
   "source": [
    "## 48. Create a summary report of the dataset including key statistics and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892eae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad092793",
   "metadata": {},
   "source": [
    "## 49. Write a function to automate the data cleaning process for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9c2016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df.dropna(inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "    return df\n",
    "\n",
    "cleaned_df = clean_data(df.copy())\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8891e8c2",
   "metadata": {},
   "source": [
    "## 50. Create a new column 'Customer_Loyalty_Score' using a simple formula on 'Customer_ID' and 'Order_Value'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b1829",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Customer_Loyalty_Score'] = df['Customer_ID'] * df['Order_Value']\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
